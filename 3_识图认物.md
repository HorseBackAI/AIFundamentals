[//]: # (Image References)

[image1]: ./Images/ZP03.jpg
[image2]: ./Images/ZP02.jpg
[image3]: ./Images/ObjectRecognition01.jpg
[image4]: ./Images/ImageRGB01.jpg
[image5]: ./Images/ImageFeatureExtraction01.jpg
[image6]: ./Images/Convolution00.jpg
[image7]: ./Images/Convolution01.jpg
[image8]: ./Images/Convolution02.jpg
[image9]: ./Images/Convolution03.jpg
[image10]: ./Images/HOG01.jpg
[image11]: ./Images/HOG02.png
[image12]: ./Images/HOG03.png
[image13]: ./Images/HOG04.png
[image14]: ./Images/HOG05.png
[image15]: ./Images/ZP04.jpg
[image16]: ./Images/CannyEdgeDetection01.png
[image17]: ./Images/VehicleDetection01.png
[image18]: ./Images/Convolution04.jpg
[image19]: ./Images/ImageNet01.jpg
[image26]: ./Images/TraditionalClfvsDNN.jpg
[image20]: ./Images/AlexNet01.jpg
[image21]: ./Images/BackPropagation01.jpg
[image22]: ./Images/MultipleKernelsConvolution01a.jpg
[image23]: ./Images/Maxpooling01.jpg
[image24]: ./Images/NonlinearActivation01.jpg
[image25]: ./Images/Fitting01.jpg
[image27]: ./Images/Learning02a.jpg
[image28]: ./Images/FullyConnected01.png
[image29]: ./Images/FullyConnected02.png
[image30]: ./Images/FullyConnected03a.png
[image31]: ./Images/FullyConnected04a.png
[image32]: ./Images/FullyConnected05a.png
[image33]: ./Images/Multi-classes02a.jpg
[image34]: ./Images/FullyConnectedLayer.png

# 第三章：识图认物

## To learn

- 应用：
	+ 物体识别 Object Recoginiiton
	+ 物体检测 Object Detection
	+ 人脸识别 Face Recognition
- 图像特征 

---

- 分类任务的两大步骤：
	1. 提取特征
	2. 根据这些特征来分类

---

- 计算机眼中的图像
- 利用卷积 Convolution 从图像中提取特征：人为设计好的办法

---

- 使用深度神经网络 Deep Neural Networks 来识图
	+ 学习如何自动地从图像中提取特征
	+ 结构：
		* 卷积层，全连接层 Fully Connected，归一化指数层 Softmax
		* 非线性激活层 Non-linear Activation，池化层 Pooling
	+ 训练方法：反向传播 Back Propagation

---

- 网不厌深
	+ 深度之助
	+ 深度之难
		* 过拟合和欠拟合 Overfitting and Underfitting
		* 梯度消失 Gradient Vanish


## 1. 从应用开始了解

![alt text][image2]

![alt text][image1]


为什么？

难道我的 ______ 不明显？

...

人脸的 _______ 都包括什么？

...

### 一朵经过测量的鸢尾花 和 我

![alt text][image15]

鸢尾花分类，根据特征：（x1, x2）

**人脸**分类，根据**特征**：

- 复杂，不再那么简单、易表述（表征）
- 稳定，不受一些可变因素的影响，e.g. 位移，遮挡，变形～～岁月 : )

再进一步：人脸是图像：**图像的特征**

- 颜色
- 边缘
- 纹理

那么，分类（识别）任务变难了！

而实际上，如我们所知，这些任务到目前已经解决得不错了，特别是很多已经工程和商业应用了：

- **物体识别 Recognition**：图中是什么？
- **物体检测 Detection**：在图中什么位置？
- **人脸识别**：谁？

这也是这次（第三次）人工智能快速发展的起始。


## 2. 完成分类（识别）任务要干两步

![alt text][image3]

**1）从图像中提取出特征，2）用这些特征来分类（识别）物体**

线性SVM：一种**分类器**

[回顾SVM](./2_察异辨花.md)：什么是支持向量？大致算法是怎样的？

## 3. 计算机眼中的图像

![alt text][image5]

![alt text][image4]

- 3个色彩（Red Green Blue）矩阵：**图像是矩阵**
- 每个点：一个像素：**0～255中一个整数**：代表色彩的强度
- (255, 0, 0) 红色，(0, 255, 0) 绿色
- 那么，(255, 255, 255) 和 (0, 0, 0) 分别是什么颜色？

...


**计算机找出图像中的特征：有相当的困难**

但是，什么事架不住人们去琢磨，特别是**用数学**去琢磨、去试～～ : )


## 4. 利用卷积 Convolution 从图像中提取特征

先看看效果：

[![alt text][image16]](https://s3.cn-north-1.amazonaws.com.cn/u-vid-hd/Av2GsgQWX8I.mp4)

找到图中边缘：**Canny Edge** Detection：一种**卷积**计算

其实就是一种再基础不过的计算～来，一起算算

![alt text][image6]

这就是**卷积**：一个短向量（小滑块）**内积**一个长向量的对应元素，小滑块在大向量上滑一趟，每滑一步都计算出一个内积（一个数），这些数依序排一起，便得到一个新的向量。

好神奇的名字：数学家非常“擅长”起名，真不知道这是为什么 : )

对于矩阵也一样，一个小矩阵 内积 一个大矩阵 ... 得到一个新的矩阵（图像）

![alt text][image7]

但：神奇的事就这么发生了

![alt text][image18]

![alt text][image9]

从图像中提取出了边缘：特征耶！

![alt text][image8]

So, 卷积：通过这样很基础的计算，生成了一个新的图像；

而这个新的图像：从原图中，提取出了特征，比如边缘。

#### HOG 方向梯度直方图

另一种更复杂而有效的用来提取图中特征的方法， Histogram of Oriented Gradients

![alt text][image10]

来看一组更清楚的图片：识别边缘：以这样的特征来识别车辆

![alt text][image11]

![alt text][image12]

![alt text][image13]

![alt text][image14]

下面就是用HOG来找图中边缘，从而探测出车辆的：

[![alt text][image17]](https://s3.cn-north-1.amazonaws.com.cn/u-vid-hd/ioaSZFCn3iI.mp4)

这样，我们有效地提取了边缘特征，通过 Canny Edge 和 HOG 这样的技术。

但是，这些特征提取是人为预先设计好的，有没有更加自动化的办法呢？


## 5. 使用深度神经网络 Deep Neural Networks 来识图

### 瓶颈

![alt text][image19]

2012年之前，识别的准确率最高在70%多，还不能实现工程和商业实用

基于人工设计的特征：这种方法遇到了瓶颈。

怎么突破、怎么提高识别准确率？

...

2012年，**AlexNet“横空出世”**，识别准确率提升了10个百分点，然后基于深度神经网络的**深度学习起飞了**～～

Why?

![alt text][image26]

因为**另辟蹊径**：为了解题，与其为我们手把手把什么都设计好，不用让我们自己学、自己摸索出解题办法～～因为这次我们有了：

1. 超越以往的**物质基础**：**深度神经网络**～～而这样的“大脑”已经足够精巧，能够解决识别物体这样复杂的问题～～输入一组数（比如图像矩阵），输出一组数（比如各个类别的概率）
2. 有效的**学习（训练）方法**：输入一组组数（图像），计算出（预测的）分类，与真实的分类相比较，看分错了多少，**聚焦在这些分错的样本上，逐步修改“大脑”里的参数**，从而一步步减少分类错误

有了物质基础和训练方法，我们就可以把 **特征提取** 和 **分类** 放在一起来**训练**～～从而搞定分类任务：

1. **自动**提取特征，不再需要人工设计特征啦
2. 自动根据这些特征来分类（识别物体）

自己一气儿干下来！

### “大脑”结构

AlexNet的深度神经网络结构

![alt text][image20]

1. **卷积**：提取出一个个特征（生成一个个特征图）
2. **非线性激活**（ReLU)：提取更复杂的特征，分更复杂的类；并留存住每次特征提取、分类的结果
3. **池化**：降低特征图的分辨率，就是图的尺寸
4. **全连接**：能分更复杂类的感知器（分类器），回忆判断录取与否的那个例子～～根据提取的特征，计算出每一类的输出值
5. **归一化指数**（softmax）：把全连接分类器的输出值换算成每一个类的概率

### 训练

![alt text][image21]

![alt text][image27]

训练：根据输入输出数据对中分错的样本，来反向调整**深度神经网络的所有参数**～～别怕：**自动地**，所以叫机器学习嘛 : ) ～～一种优化算法，叫**反向传播 Back-propagation**

- 下山：逐渐减少错误
- 沿最陡的方向下山：
	+ w = w - gradient × learning rate
	+ 参数 = 参数 - 梯度（下山方向） × 学习率（每步迈多远）

看动画：[训练网络、调整网络参数](http://www.emergentmind.com/neural-network)

### 卷积：提取特征

一个个**卷积核（小滤镜）**，每个滤镜扫一遍原始图或前面已经提取出来的**特征图**，生成（提取出）一个新的特征图

![alt text][image22]

### 全连接：能分更复杂类的分类器

![alt text][image34]

能分曲线、曲面

![alt text][image28]

其实就是：**若干个线性分类组合在一起**来实现的

![alt text][image29]

![alt text][image30]

把两个“录取”分类器组合在一起：**全连接**

![alt text][image31]

![alt text][image32]

### 非线性激活：曲线、曲面，留存结果

![alt text][image24]

保留住每次变换的效果

Rectified 线性整流：计算最快，效果也不错

### 池化层：减小特征图尺寸

![alt text][image23]

不用看那么“泛”，而是要“深”：降低分辨率，只要提取出特征即可

### 归一化指数层

![alt text][image33]


## 6. 先小结一下：深度神经网络

- 物质基础：能识别出更复杂的图（人脸）了～～这么多不同功能的计算层组成～～一层层计算出来：更具表达能力
- 根据输入输出的数据，特征提取 + 分类 一起来训练：自动，更强大


## 7. 网不厌深

越来越强大，解决问题也越来越有挑战性。

但是，也存在训练上的问题。

![alt text][image25]

- 欠拟合：机器（脑袋）不够精巧，往往是物质基础不够
- 过拟合：机器足够精巧，但太钻牛角尖了，训练样本训练过多，而无法发现真正的分类规律


梯度消失：网络过深，错误（反向）传播得不够明显了，不足以调整参数了。








