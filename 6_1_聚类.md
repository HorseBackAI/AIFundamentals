[//]: # (Image References)

[image1]: ./Images/Iris_setosa.jpg
[image2]: ./Images/Iris_versicolor.jpg
[image3]: ./Images/Iris_virginica.jpg
[image4]: ./Images/Iris_cluster_groud_truth.png
[image5]: ./Images/Clustering_marketing.png
[image6]: ./Images/Clustering_insurance.png
[image7]: ./Images/Iris_clustering.png

# 第六章：聚类 Clustering

“无师自通”：**Unsupervised learning**

没有事先标注好的类别了 No target labels any more

We have to find some patterns in the data points to cluster (note: not use the verb 'classify' here) data points into different classes. 

Clustering.

## To learn

- 问题：What if AI doesn't know the breeds (classes) of irises? How can it classify them?

---

- K-means clustering
	* Algorithm: 
		+ [Illustration](https://www.naftaliharris.com/blog/visualizing-k-means-clustering/)
		+ 1) Initialize centroids --> 2) assign samples --> 3) re-vote centroids
	* Issues with K-means
	* [Example code: Irises clustering](https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html)

---

- Human face clustering
	* Pipeline: 1) face detection --> 2) [face frontalization](https://github.com/dougsouza/face-frontalization) --> 3) feature extraction: face encoding --> 4) face clustering
	* [Face recognition example code](https://github.com/ageitgey/face_recognition): Key point here is actually about face encoding (feature extraction) by deep learning.

## 1. Applications of Clustering

**Find an intrinsic grouping in set of unlabeled examples.**

Of great practical utility:

- Marketing

![alt text][image5]

- Biology and medicine
- Insurance

![alt text][image6]

Like deep learning 下山 down the hill, it’s an **Optimization Problem**.

Need an objective:

- Low intra-cluster dissimilarity 组内类似
- High inter-cluster dissimilarity 组间不像


## 2. Any Idea?

Iris setosa

![alt text][image1]

Iris versicolor

![alt text][image2]

Iris virginica

![alt text][image3]

![alt text][image4]

## 3. K-means Clustering

### Algorithm

[Algorithm and example from lecture note of MIT 6.002](./6_2_Kmeans_mit.pdf)

1. Initialize centroids
2. (Re-)assign samples to closest centroid
3. Re-vote centroids by averaging samples

Repeat 2 thru 3 till centroids don't change

[Another illustration](https://www.naftaliharris.com/blog/visualizing-k-means-clustering/)

### Issues with K-means

Bad initial centroids and wrong K would lead to nonsense.

### [Example code: Irises clustering](https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html)
	
	# No target classes
	X = iris.data
	...
	
	# 3次聚类：分别聚8类，3类，3类、但只初始选中心一次
	estimators = [('k_means_iris_8', KMeans(n_clusters=8)),
	              ('k_means_iris_3', KMeans(n_clusters=3)),
	              ('k_means_iris_bad_init', KMeans(n_clusters=3, n_init=1,
	                                               init='random'))]
	...
	# 每一次聚类
	for name, est in estimators:
	    ...
	    est.fit(X)   # K-means clustering
	    labels = est.labels_   # Clustering results
	    
	    ax.scatter(X[:, 3], X[:, 0], X[:, 2],
	               c=labels.astype(np.float), edgecolor='k')


![alt text][image7]

## 4. Face Clustering

### Pipeline

1. Face detection
2. [Face frontalization](https://github.com/dougsouza/face-frontalization)
3. **Feature extraction: face encoding:** Key point by deep learning.
4. Face clustering

### [Face recognition example code](https://github.com/ageitgey/face_recognition)

`face_recognition` and `face_detection`

- Search applications what you may be interested in
- Many out-of-box features can be played around. You may get some gut feeling and then utilize them to do something. : )